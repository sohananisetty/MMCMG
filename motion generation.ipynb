{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb3b07-c8eb-45c6-98d3-3b60465437ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f954b1-cb9b-4804-baa3-8d3ff1767409",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d2c44f-6d0d-40a0-bc35-87b63a8f840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1258f23c-26b7-45b0-b5d5-5dc740f24a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a9ec4f-a702-4234-a7e2-20b17c24f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllFile(base):\n",
    "    file_path = []\n",
    "    for root, ds, fs in os.walk(base, followlinks=True):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            file_path.append(fullname)\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a983f16-1f57-477d-9ad5-53864d65a93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ce4c3a9-ac49-453b-ba6d-2a45069b4c2b",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8809e560-bb5b-4113-a19b-8e96f72e0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_vqvae import cfg, get_cfg_defaults\n",
    "def load_vqvae(gen_cfg):\n",
    "\n",
    "    body_cfg = get_cfg_defaults()\n",
    "    body_cfg.merge_from_file(gen_cfg.vqvae.body_config)\n",
    "    body_model = (\n",
    "        instantiate_from_config(body_cfg.vqvae).to(device).eval()\n",
    "    )\n",
    "    body_model.load(os.path.join(body_cfg.output_dir, \"vqvae_motion.pt\"))\n",
    "\n",
    "    if gen_cfg.vqvae.left_hand_config is  None and gen_cfg.vqvae.right_hand_config is None:\n",
    "        return body_model, body_cfg\n",
    "    \n",
    "    if gen_cfg.vqvae.left_hand_config is not None:\n",
    "        left_cfg = get_cfg_defaults()\n",
    "        left_cfg.merge_from_file(gen_cfg.vqvae.left_hand_config)\n",
    "        left_hand_model = instantiate_from_config(left_cfg.vqvae).to(device).eval()\n",
    "        left_hand_model.load(\n",
    "            os.path.join(left_cfg.output_dir, \"vqvae_motion.pt\")\n",
    "        )\n",
    "    else:\n",
    "        left_hand_model = None\n",
    "        \n",
    "    if gen_cfg.vqvae.right_hand_config is not None:\n",
    "        right_cfg = get_cfg_defaults()\n",
    "        right_cfg.merge_from_file(gen_cfg.vqvae.right_hand_config)\n",
    "        right_hand_model = instantiate_from_config(right_cfg.vqvae).to(device).eval()\n",
    "        right_hand_model.load(\n",
    "            os.path.join(right_cfg.output_dir, \"vqvae_motion.pt\")\n",
    "        )\n",
    "    else:\n",
    "        right_hand_model = None\n",
    "\n",
    "    return body_model, left_hand_model , right_hand_model , body_cfg , left_cfg , right_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03978b4-2fc1-4910-90fd-fb50a35666b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "924bb3c9-cfe7-418a-9eba-07c88fd4bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bkn_to_motion( codes, dset , remove_translation = True):\n",
    "    # codes b k n\n",
    "\n",
    "    k = codes.shape[1]\n",
    "    mrep = dset.motion_rep\n",
    "\n",
    "    if k == 1:\n",
    "        if mrep == MotionRep(\"body\"):\n",
    "\n",
    "            body_inds = codes[:, 0]\n",
    "            body_motion = body_model.decode(body_inds[0:1]).detach().cpu()\n",
    "\n",
    "            if remove_translation:\n",
    "                z = torch.zeros(\n",
    "                    body_motion.shape[:-1] + (2,),\n",
    "                    dtype=body_motion.dtype,\n",
    "                    device=body_motion.device,\n",
    "                )\n",
    "                body_motion = torch.cat(\n",
    "                    [body_motion[..., 0:1], z, body_motion[..., 1:]], -1\n",
    "                )\n",
    "\n",
    "            body_M = dset.toMotion(\n",
    "                body_motion[0],\n",
    "                motion_rep=MotionRep(\"body\"),\n",
    "                hml_rep=body_cfg.dataset.hml_rep,\n",
    "            )\n",
    "\n",
    "            return body_M\n",
    "\n",
    "        elif mrep == MotionRep(\"left_hand\"):\n",
    "\n",
    "            left_inds = codes[:, 0]\n",
    "            left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "            left_M = dset.toMotion(\n",
    "                left_motion[0],\n",
    "                motion_rep=MotionRep(left_cfg.dataset.motion_rep),\n",
    "                hml_rep=left_cfg.dataset.hml_rep,\n",
    "            )\n",
    "            return left_M\n",
    "\n",
    "        elif mrep == MotionRep(\"right_hand\"):\n",
    "            right_inds = codes[:, 0]\n",
    "            right_motion = (\n",
    "                right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "            )\n",
    "            right_M = dset.toMotion(\n",
    "                right_motion[0],\n",
    "                motion_rep=MotionRep(right_cfg.dataset.motion_rep),\n",
    "                hml_rep=right_cfg.dataset.hml_rep,\n",
    "            )\n",
    "            return right_M\n",
    "\n",
    "    if k == 2:\n",
    "        left_inds = codes[:, 0]\n",
    "        right_inds = codes[:, 1]\n",
    "\n",
    "        left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "        right_motion = right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "\n",
    "        left_M = dset.toMotion(\n",
    "            left_motion[0],\n",
    "            motion_rep=MotionRep(left_cfg.dataset.motion_rep),\n",
    "            hml_rep=left_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        right_M = dset.toMotion(\n",
    "            right_motion[0],\n",
    "            motion_rep=MotionRep(right_cfg.dataset.motion_rep),\n",
    "            hml_rep=right_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        hand_M = left_M + right_M\n",
    "        hand_M.motion_rep = MotionRep.HAND\n",
    "        hand_M.hml_rep = \"\".join(\n",
    "            [i for i in left_M.hml_rep if i in right_M.hml_rep]\n",
    "        )\n",
    "        return hand_M\n",
    "\n",
    "    if k == 3:\n",
    "        left_inds = codes[:, 1]\n",
    "        right_inds = codes[:, 2]\n",
    "        body_inds = codes[:, 0]\n",
    "        body_motion = body_model.decode(body_inds[0:1]).detach().cpu()\n",
    "\n",
    "        \n",
    "        if remove_translation:\n",
    "            z = torch.zeros(\n",
    "                body_motion.shape[:-1] + (2,),\n",
    "                dtype=body_motion.dtype,\n",
    "                device=body_motion.device,\n",
    "            )\n",
    "            body_motion = torch.cat([body_motion[..., 0:1], z, body_motion[..., 1:]], -1)\n",
    "\n",
    "        left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "        right_motion = right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "\n",
    "        body_M = dset.toMotion(\n",
    "            body_motion[0],\n",
    "            motion_rep=MotionRep(\"body\"),\n",
    "            hml_rep = body_cfg.dataset.hml_rep)\n",
    "\n",
    "        left_M = dset.toMotion(\n",
    "            left_motion[0],\n",
    "            motion_rep=MotionRep(\"left_hand\"),\n",
    "            hml_rep=left_cfg.dataset.hml_rep)\n",
    "        right_M = dset.toMotion(\n",
    "            right_motion[0],\n",
    "            motion_rep=MotionRep(\"right_hand\"),\n",
    "            hml_rep=right_cfg.dataset.hml_rep)\n",
    "        full_M = dset.to_full_joint_representation(body_M, left_M, right_M)\n",
    "        return full_M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34242b5-59c5-4759-b2ae-03a381a91228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "835eda0f-69cc-4cfc-bf52-24d46d640e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_cfg_gprvc = get_cfg_defaults()\n",
    "body_cfg_gprvc.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_full_gpvc/vqvae_full_gpvc.yaml\")\n",
    "full_gpvc = instantiate_from_config(body_cfg_gprvc.vqvae).to(device).eval()\n",
    "full_gpvc.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/vqvae/vqvae_full_gpvc/vqvae_motion.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0604fd-7aa1-430f-a3ed-f1ba08b99049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10256640-d2ae-4e9f-88e3-007f290c1ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4974404e-64b4-4b97-8758-1b616bc9d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core import MotionTokenizerParams, pattern_providers\n",
    "\n",
    "from core.param_dataclasses import pattern_providers\n",
    "from core.datasets.multimodal_dataset import MotionIndicesAudioTextDataset, load_dataset_gen, simple_collate\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from core.models.generation.muse import MLMModel, MotionMuse\n",
    "import einops\n",
    "from configs.config_t2m import get_cfg_defaults as muse_get_cfg_defaults\n",
    "from core import MotionTokenizerParams\n",
    "\n",
    "from core.models.generation.translation_transformer import TranslationTransformer\n",
    "from core.datasets.text_encoders import BERTConditioner, ClipConditioner, T5Conditioner, parse_prompt_attention\n",
    "from core.datasets.audio_encoders import EncodecConditioner, LibrosaConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df23b9-8f22-4b80-a443-aee5d7b78108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60126d73-b0da-411e-bc8c-0585da577f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = muse_get_cfg_defaults()\n",
    "gen_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse_critic/motion_muse_critic.yaml\")\n",
    "gen_cfg.freeze()\n",
    "tranformer_config = gen_cfg.motion_generator\n",
    "fuse_config = gen_cfg.fuser\n",
    "pattern_config = gen_cfg.codebooks_pattern\n",
    "dataset_args = gen_cfg.dataset\n",
    "\n",
    "target = tranformer_config.pop(\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84a5916-e1ee-42e8-a5d0-8ee282445b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_gen = MotionMuse(tranformer_config , fuse_config , pattern_config).to(device)\n",
    "# motion_gen = torch.compile(motion_gen)\n",
    "pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse_critic/motion_muse.pt\", map_location=\"cuda\")\n",
    "motion_gen.load_state_dict(pkg[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de10660-1701-4454-ba0f-b4d68a10506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110000.], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkg[\"steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e73b41b9-b2cc-40be-a76a-fe26115d05f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync is turned on False\n",
      "loaded model with  0.03015906736254692 tensor([110000.], device='cuda:0') steps\n"
     ]
    }
   ],
   "source": [
    "body_model, body_cfg = load_vqvae(gen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dfda37ab-a17c-44a5-9246-64f6ef445be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg2 = muse_get_cfg_defaults()\n",
    "gen_cfg2.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse_hands/motion_muse_hands.yaml\")\n",
    "gen_cfg2.freeze()\n",
    "tranformer_config2 = gen_cfg2.motion_generator\n",
    "fuse_config2 = gen_cfg2.fuser\n",
    "pattern_config2 = gen_cfg2.codebooks_pattern\n",
    "dataset_args2 = gen_cfg2.dataset\n",
    "\n",
    "_ = tranformer_config2.pop(\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e4b2322f-5275-42ae-bffe-c1f5b5465f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_gen2 = MotionMuse(tranformer_config2 , fuse_config2 , pattern_config2).to(device)\n",
    "# motion_gen = torch.compile(motion_gen)\n",
    "pkg2 = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_muse_hands/motion_muse.pt\", map_location=\"cuda\")\n",
    "motion_gen2.load_state_dict(pkg2[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8806b6e9-68d1-40df-9785-69b8380670dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from core.models.generation.translation_transformer import TranslationTransformer\n",
    "# from configs.config_t2m import get_cfg_defaults as trans_get_cfg_defaults\n",
    "\n",
    "# t_cfg = trans_get_cfg_defaults()\n",
    "# t_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_translation/motion_translation.yaml\")\n",
    "# # t_cfg.freeze()\n",
    "\n",
    "# tranformer_config2 = t_cfg.translation_transformer\n",
    "# fuse_config2 = t_cfg.fuser\n",
    "# dataset_args2 = t_cfg.dataset\n",
    "\n",
    "# target2 = tranformer_config2.pop(\"target\")\n",
    "\n",
    "# trans_former = TranslationTransformer(tranformer_config2, fuse_config2).to(device)\n",
    "# trans_former.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/checkpoints/motion_translation/translation_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e876039b-5823-4180-ab2f-bc6bf213d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, left_hand_model , right_hand_model , _ , left_cfg , right_cfg = load_vqvae(gen_cfg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95161c3-a1d0-4903-83e3-c9116a59576c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bb7f4799-8e44-44e3-aeb5-cf257da60c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            audio_max_length_s=dataset_args.audio_max_length_s,\n",
    "            pad_id = MotionTokenizerParams(tranformer_config.num_tokens).pad_token_id,\n",
    "            fps=30/4,\n",
    "            # device = \"cpu\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fb234-c418-4905-af0a-fc8a5eb89445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "981465d1-3e8a-4a0d-827d-b0616986a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.base_dataset import BaseMotionDataset\n",
    "base_dset = BaseMotionDataset(motion_rep=MotionRep.BODY , hml_rep= \"gpvc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "382010c4-1a69-4f63-9cdd-bbd9303766d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/beat/1_wayne_0_1_1.wav\"\n",
    "choreo = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\"\n",
    "mbr = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/aist/mBR0.wav\"\n",
    "mj = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/aist/mJB0.wav\"\n",
    "wild =  \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/wild/despacito.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a2d5e-b325-47d6-a3fb-d858b79d4eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4bfc0cd9-4ee8-48ca-a9a5-f81fa4bba7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 33.00it/s]\n"
     ]
    }
   ],
   "source": [
    "_, conditions = condition_provider(raw_audio= None, raw_text=\"A person walks forwards and then sits.\" )\n",
    "_, neg_conditions = condition_provider(raw_text=\"body movement\")\n",
    "gen_ids = motion_gen.generate(conditions =conditions, neg_conditions = None, duration_s = 4, temperature = 0.2 ,timesteps=24, cond_scale = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "75155b52-4c68-4bd0-be28-a99a668529f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 49.50it/s]\n"
     ]
    }
   ],
   "source": [
    "gen_ids2 = motion_gen2.generate(conditions =conditions, neg_conditions = None, duration_s = 4, temperature = 0.2 ,timesteps=24, cond_scale = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7000944d-95c3-4bd1-aaf0-e8ada59dc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gen_ids = torch.cat([gen_ids , gen_ids2] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0ea26ce6-95ca-48d5-8143-e1c7acdc9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_motion = bkn_to_motion(all_gen_ids, base_dset)\n",
    "base_dset.render_hml(\n",
    "                    gen_motion,\n",
    "                    f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/gen_novel_full.gif\",\n",
    "                    zero_trans = True,\n",
    "                    zero_orient = True,\n",
    "    \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b319fee-b57b-4a90-b091-b293bfd651c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(open(f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/gen_novel_full.gif\",'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06083edf-23fe-464c-a5e3-5cf6d61ef12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9306ed-f40f-49a5-bcfb-28830f55cad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09077072-d766-46bd-9f07-6c4c702d4df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8c101-85ac-469a-b880-7fae464ca2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03c409a1-d9e1-494e-88de-2ac888e75dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, conditions = condition_provider(raw_audio= beat, raw_text=\"a person gives a speech angrily with exagerrated hand movements\"  , audio_max_length_s=16)\n",
    "_, neg_conditions = condition_provider(raw_text=\"dancing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69e8510e-4c9c-448a-9924-c278cc3d1acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 480, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "172b258d-7ddf-4775-9101-f4111595624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, conditions = condition_provider(raw_audio= None , raw_text = \"a person jumps once and turns around\")\n",
    "_, neg_conditions = condition_provider(raw_text=\"jittery motion, slow, stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5be9cc36-1916-4bb5-b5ae-6cf522df74ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions[\"audio\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8d9d4d8-49cb-4280-9cb9-513ea94212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_audio= None\n",
    "raw_text = \"a person jumps once and turns around\"\n",
    "neg_text = None\n",
    "neg_audio = None\n",
    "critic = True\n",
    "nme = \"\" if raw_audio is None else os.path.basename(raw_audio).split('.')[0]\n",
    "nme += f\"{raw_text}_{critic}\"\n",
    "nme += \"_neg_\"\n",
    "nme = nme + (\"\" if neg_audio is None else os.path.basename(neg_audio).split('.')[0])\n",
    "nme = nme + (\"\" if neg_text is None else f\"{neg_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d039dc76-ed43-4617-a532-bfceb9b73992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a person jumps once and turns around_True_neg_'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a8e75a9-700f-46da-b452-b313153c76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, conditions = condition_provider(raw_audio= raw_audio, raw_text= raw_text   )\n",
    "_, neg_conditions = condition_provider(raw_text=neg_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29789c-565c-49f4-9692-6debd904968d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "03fabce1-f1a6-4dec-a759-d5f55cab31da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb5ffd1a-0075-4268-a4d2-122ebc443a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 72/72 [00:03<00:00, 23.27it/s]\n"
     ]
    }
   ],
   "source": [
    "gen_ids = motion_gen.generate(conditions =conditions, neg_conditions = None, \\\n",
    "                              duration_s = 4, temperature = 1.0 ,timesteps=24, \\\n",
    "                              cond_scale = 8,force_not_use_token_critic = critic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86afb91d-0822-4489-9dd9-411be0167c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba52b6d5-afb9-4212-9bd1-ae7ecfc63c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion representation: full, type: gpvc, num joints: 52, dim: 317\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b75f0159-8210-4227-b3eb-1f4f69fb593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_motion = bkn_to_motion(gen_ids, base_dset)\n",
    "base_dset.render_hml(\n",
    "                    gen_motion,\n",
    "                    f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/gen_movel.gif\",\n",
    "                    zero_trans = True,\n",
    "                    zero_orient = True,\n",
    "    \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "242cc0e1-c563-4749-93a8-0d60c2d314b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(open(f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/{nme}.gif\",'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19a553-65c3-42ca-8143-6fa97150aa94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c58698-ed2b-4600-bb5a-62eb550f18cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68235ea1-2430-48a5-9c73-bb5d23cabb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd45edc-f434-4ddb-990a-75861bb063a9",
   "metadata": {},
   "source": [
    "## Generate aniamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbda16be-3bbb-449a-bd6c-5413ece5d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.generation.muse import generate_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60981426-e813-4714-aa9f-2b0f9c4a2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionTokenizerParams\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from core.models.generation.muse import MotionMuse\n",
    "\n",
    "import einops\n",
    "from configs.config_t2m import get_cfg_defaults as muse_get_cfg_defaults\n",
    "from core import MotionTokenizerParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165fb3e-96fa-4348-b928-5bbe2e9abbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c10f5d9e-26ae-4e14-ab01-ea11092b6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = muse_get_cfg_defaults()\n",
    "gen_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/checkpoints/motion_muse_body_hands/motion_muse_body_hands.yaml\")\n",
    "gen_cfg.freeze()\n",
    "tranformer_config = gen_cfg.motion_generator\n",
    "fuse_config = gen_cfg.fuser\n",
    "dataset_args = gen_cfg.dataset\n",
    "\n",
    "target = tranformer_config.pop(\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdc21c7f-f0b2-411f-a213-4275d9393198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-3:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "motion_gen = MotionMuse(tranformer_config , fuse_config).to(device).eval()\n",
    "pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/checkpoints/motion_muse_body_hands/motion_muse.pt\", map_location=\"cuda\")\n",
    "motion_gen.load_state_dict(pkg[\"model\"])\n",
    "motion_gen = torch.compile(motion_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3476d65d-0228-47da-8fe0-f87799e094ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_model , body_cfg= load_vqvae(gen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83af976b-cf88-4f47-818a-0ca1968a4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync is turned on False\n",
      "loaded model with  0.03015906736254692 tensor([110000.], device='cuda:0') steps\n"
     ]
    }
   ],
   "source": [
    "body_model, left_hand_model , right_hand_model , body_cfg , left_cfg , right_cfg = load_vqvae(gen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc9c6f21-47c2-4b23-90e8-b936d0376cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|█████████████████████████████████████████████████████| 809/809 [00:00<00:00, 329kB/s]\n",
      "model.safetensors: 100%|██████████████████████████████████████████| 93.1M/93.1M [00:02<00:00, 45.5MB/s]\n",
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "preprocessor_config.json: 100%|████████████████████████████████████████| 234/234 [00:00<00:00, 100kB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            audio_max_length_s=dataset_args.audio_max_length_s,\n",
    "            pad_id = MotionTokenizerParams(tranformer_config.num_tokens).pad_token_id,\n",
    "            fps=30/4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd232e3-fb1b-4a47-94a9-52c27d11d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.base_dataset import BaseMotionDataset\n",
    "base_dset = BaseMotionDataset(motion_rep=MotionRep.FULL , hml_rep= \"gpvc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "278a094a-3741-4ffd-b899-ab2db18b14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.joints2bvh import Joint2BVHConvertor\n",
    "converter = Joint2BVHConvertor(mode = \"smplx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97326e0a-0fa8-4342-8a75-1f1e71bbdcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8d121-6950-4a3d-8437-9661ddb07323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e5dcf4d-c45c-430d-bffc-31b020fb18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/beat/1_wayne_0_1_1.wav\"\n",
    "choreo = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\"\n",
    "mbr = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/aist/mBR0.wav\"\n",
    "mj = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/aist/mJB0.wav\"\n",
    "wild =  \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/wild/despacito.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39769428-ba3a-4785-b2d0-bd62b79be0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_clip =  wild\n",
    "text_ = \"A person dancing energetically\"\n",
    "neg_text = None\n",
    "use_token_critic = True\n",
    "temperature = 0.6\n",
    "\n",
    "sve_file = '|'.join(t for t in text_) if isinstance(text_ , list) else f\"{text_}\"\n",
    "sve_file += \"\" if aud_clip is None else f\"{os.path.basename(aud_clip).split('.')[0]}\"\n",
    "sve_file += f\"_use_critic_{use_token_critic}_{temperature}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e48346c3-68f0-438c-b415-3f18c6a53973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person dancing energeticallydespacito_use_critic_True_0.6\n"
     ]
    }
   ],
   "source": [
    "print(sve_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e74133cf-25b5-42e3-9894-f5f786256e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 45.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 47.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 47.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 47.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 47.02it/s]\n"
     ]
    }
   ],
   "source": [
    "all_ids_body = generate_animation(motion_gen , condition_provider ,overlap = 10, duration_s = 30 , temperature = temperature, aud_file=aud_clip, text = text_ , neg_text=neg_text,use_token_critic = use_token_critic, timesteps = 24 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4b7bc-d75a-4ff7-9c49-00eb9964432f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4aba71b-de46-4655-96b4-52f53cc5501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_motion = bkn_to_motion(all_ids_body, base_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc431dd-4229-4300-b8e4-371b14d0b286",
   "metadata": {},
   "source": [
    "### Save as gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3c325cc-a1d1-4a61-bc93-eb597d4e3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dset.render_hml(\n",
    "                    gen_motion,\n",
    "                    f\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/renders/{sve_file}.gif\",\n",
    "                    zero_trans = True,\n",
    "                    zero_orient = True,\n",
    "    \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b674f4-d492-498d-9ed5-75bf5e21c178",
   "metadata": {},
   "source": [
    "### Save as BVH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f4dc1-6de9-4466-b29f-3249fb2538ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0651340d-7d18-4bfc-a8fa-8965727c1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_inv = base_dset.inv_transform(gen_motion)\n",
    "motion_xyz = base_dset.to_xyz(motion_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d04283bc-68b7-4c50-99c9-b804864443d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ik_joint = converter.convert(motion_xyz.cpu().numpy(), filename=f\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/renders/{sve_file}.bvh\", iterations=10, foot_ik = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d592a73-7f61-48e0-af60-396619c06e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcbb83c1-34ad-4959-92cf-d30d453a7511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568380f8-3c35-4635-9ac8-ae3d20ff755a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ace5f-c36f-4ff3-bb27-25acab1b4fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b2fa4-dfef-4f38-a265-8d6ffbd905c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aeb855-985a-4377-9cb5-a35a98c851e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9a448-2543-41b7-86a2-4dd98791cd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c2dd6-2f75-4a46-86cf-4910de6b3719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90902baa-16e8-4eb4-ac7b-3a04e3078f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16722193-126f-4249-a173-7dd4f624494a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c5de6-cce6-4aaf-b352-90fddcfd7a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab95ff-c8c3-47c5-a49a-428c434492cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f66bd-862d-4485-9d25-1e15089b84de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf1aeb71-1581-4f34-bdce-4b2d57d26d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd697d9f-0743-4099-833a-e3a1a8ecaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import math\n",
    "\n",
    "def joinGifAud(vid , aud_clip , sve_name = \"vid\"):\n",
    "    video_clip = mp.VideoFileClip(vid)\n",
    "    audio_clip = mp.AudioFileClip(aud_clip)\n",
    "    endd = int(math.floor(min(audio_clip.end , video_clip.end)))\n",
    "    video_clip = video_clip.subclip(0, endd)\n",
    "    final_clip = video_clip.set_audio(audio_clip.subclip(0, endd))\n",
    "    save_name = os.path.basename(aud_clip).split('.')[0]\n",
    "    final_clip.write_videofile(f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/{sve_name}.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68535af4-a1b6-4c2e-b721-e5391aa8502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/beat/1_wayne_0_1_1.wav'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fad651e-3a1c-4201-b09d-b5743e58d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/1_wayne_0_1_1_use_critic_True_0.4_full.mp4.\n",
      "MoviePy - Writing audio in 1_wayne_0_1_1_use_critic_True_0.4_fullTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/1_wayne_0_1_1_use_critic_True_0.4_full.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/1_wayne_0_1_1_use_critic_True_0.4_full.mp4\n"
     ]
    }
   ],
   "source": [
    "joinGifAud(f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/2024/{sve_file}.gif\" , aud_clip , sve_name = f\"{sve_file}_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b12855-9375-41b4-8aab-a9182779431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
