{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb3b07-c8eb-45c6-98d3-3b60465437ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f954b1-cb9b-4804-baa3-8d3ff1767409",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d2c44f-6d0d-40a0-bc35-87b63a8f840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1258f23c-26b7-45b0-b5d5-5dc740f24a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import partial\n",
    "from torch import einsum, nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a9ec4f-a702-4234-a7e2-20b17c24f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllFile(base):\n",
    "    file_path = []\n",
    "    for root, ds, fs in os.walk(base, followlinks=True):\n",
    "        for f in fs:\n",
    "            fullname = os.path.join(root, f)\n",
    "            file_path.append(fullname)\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a983f16-1f57-477d-9ad5-53864d65a93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ce4c3a9-ac49-453b-ba6d-2a45069b4c2b",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8809e560-bb5b-4113-a19b-8e96f72e0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_vqvae import cfg, get_cfg_defaults\n",
    "def load_vqvae(gen_cfg):\n",
    "\n",
    "    body_cfg = get_cfg_defaults()\n",
    "    body_cfg.merge_from_file(gen_cfg.vqvae.body_config)\n",
    "    body_model = (\n",
    "        instantiate_from_config(body_cfg.vqvae).to(device).eval()\n",
    "    )\n",
    "    body_model.load(os.path.join(body_cfg.output_dir, \"vqvae_motion.pt\"))\n",
    "\n",
    "    if gen_cfg.vqvae.left_hand_config is  None and gen_cfg.vqvae.right_hand_config is None:\n",
    "        return body_model, body_cfg\n",
    "    \n",
    "    if gen_cfg.vqvae.left_hand_config is not None:\n",
    "        left_cfg = get_cfg_defaults()\n",
    "        left_cfg.merge_from_file(gen_cfg.vqvae.left_hand_config)\n",
    "        left_hand_model = instantiate_from_config(left_cfg.vqvae).to(device).eval()\n",
    "        left_hand_model.load(\n",
    "            os.path.join(left_cfg.output_dir, \"vqvae_motion.pt\")\n",
    "        )\n",
    "    else:\n",
    "        left_hand_model = None\n",
    "        \n",
    "    if gen_cfg.vqvae.right_hand_config is not None:\n",
    "        right_cfg = get_cfg_defaults()\n",
    "        right_cfg.merge_from_file(gen_cfg.vqvae.right_hand_config)\n",
    "        right_hand_model = instantiate_from_config(right_cfg.vqvae).to(device).eval()\n",
    "        right_hand_model.load(\n",
    "            os.path.join(right_cfg.output_dir, \"vqvae_motion.pt\")\n",
    "        )\n",
    "    else:\n",
    "        right_hand_model = None\n",
    "\n",
    "    return body_model, left_hand_model , right_hand_model , body_cfg , left_cfg , right_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03978b4-2fc1-4910-90fd-fb50a35666b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924bb3c9-cfe7-418a-9eba-07c88fd4bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def bkn_to_motion( codes, dset , remove_translation = True):\n",
    "    # codes b k n\n",
    "\n",
    "    k = codes.shape[1]\n",
    "    mrep = dset.motion_rep\n",
    "\n",
    "    if k == 1:\n",
    "        if mrep == MotionRep(\"body\"):\n",
    "\n",
    "            body_inds = codes[:, 0]\n",
    "            body_motion = body_model.decode(body_inds[0:1]).detach().cpu()\n",
    "\n",
    "            if remove_translation:\n",
    "                z = torch.zeros(\n",
    "                    body_motion.shape[:-1] + (2,),\n",
    "                    dtype=body_motion.dtype,\n",
    "                    device=body_motion.device,\n",
    "                )\n",
    "                body_motion = torch.cat(\n",
    "                    [body_motion[..., 0:1], z, body_motion[..., 1:]], -1\n",
    "                )\n",
    "\n",
    "            body_M = dset.toMotion(\n",
    "                body_motion[0],\n",
    "                motion_rep=MotionRep(\"body\"),\n",
    "                hml_rep=body_cfg.dataset.hml_rep,\n",
    "            )\n",
    "\n",
    "            return body_M\n",
    "\n",
    "        elif mrep == MotionRep(\"left_hand\"):\n",
    "\n",
    "            left_inds = codes[:, 0]\n",
    "            left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "            left_M = dset.toMotion(\n",
    "                left_motion[0],\n",
    "                motion_rep=MotionRep(left_cfg.dataset.motion_rep),\n",
    "                hml_rep=left_cfg.dataset.hml_rep,\n",
    "            )\n",
    "            return left_M\n",
    "\n",
    "        elif mrep == MotionRep(\"right_hand\"):\n",
    "            right_inds = codes[:, 0]\n",
    "            right_motion = (\n",
    "                right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "            )\n",
    "            right_M = dset.toMotion(\n",
    "                right_motion[0],\n",
    "                motion_rep=MotionRep(right_cfg.dataset.motion_rep),\n",
    "                hml_rep=right_cfg.dataset.hml_rep,\n",
    "            )\n",
    "            return right_M\n",
    "\n",
    "    if k == 2:\n",
    "        left_inds = codes[:, 0]\n",
    "        right_inds = codes[:, 1]\n",
    "\n",
    "        left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "        right_motion = right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "\n",
    "        left_M = dset.toMotion(\n",
    "            left_motion[0],\n",
    "            motion_rep=MotionRep(left_cfg.dataset.motion_rep),\n",
    "            hml_rep=left_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        right_M = dset.toMotion(\n",
    "            right_motion[0],\n",
    "            motion_rep=MotionRep(right_cfg.dataset.motion_rep),\n",
    "            hml_rep=right_cfg.dataset.hml_rep,\n",
    "        )\n",
    "        hand_M = left_M + right_M\n",
    "        hand_M.motion_rep = MotionRep.HAND\n",
    "        hand_M.hml_rep = \"\".join(\n",
    "            [i for i in left_M.hml_rep if i in right_M.hml_rep]\n",
    "        )\n",
    "        return hand_M\n",
    "\n",
    "    if k == 3:\n",
    "        left_inds = codes[:, 1]\n",
    "        right_inds = codes[:, 2]\n",
    "        body_inds = codes[:, 0]\n",
    "        body_motion = body_model.decode(body_inds[0:1]).detach().cpu()\n",
    "\n",
    "        \n",
    "        if remove_translation:\n",
    "            z = torch.zeros(\n",
    "                body_motion.shape[:-1] + (2,),\n",
    "                dtype=body_motion.dtype,\n",
    "                device=body_motion.device,\n",
    "            )\n",
    "            body_motion = torch.cat([body_motion[..., 0:1], z, body_motion[..., 1:]], -1)\n",
    "\n",
    "        left_motion = left_hand_model.decode(left_inds[0:1]).detach().cpu()\n",
    "        right_motion = right_hand_model.decode(right_inds[0:1]).detach().cpu()\n",
    "\n",
    "        body_M = dset.toMotion(\n",
    "            body_motion[0],\n",
    "            motion_rep=MotionRep(\"body\"),\n",
    "            hml_rep = body_cfg.dataset.hml_rep)\n",
    "\n",
    "        left_M = dset.toMotion(\n",
    "            left_motion[0],\n",
    "            motion_rep=MotionRep(\"left_hand\"),\n",
    "            hml_rep=left_cfg.dataset.hml_rep)\n",
    "        right_M = dset.toMotion(\n",
    "            right_motion[0],\n",
    "            motion_rep=MotionRep(\"right_hand\"),\n",
    "            hml_rep=right_cfg.dataset.hml_rep)\n",
    "        full_M = dset.to_full_joint_representation(body_M, left_M, right_M)\n",
    "        return full_M\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde3fc8-0e16-421a-aefa-0df66b37e9a4",
   "metadata": {},
   "source": [
    "## Refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34242b5-59c5-4759-b2ae-03a381a91228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835eda0f-69cc-4cfc-bf52-24d46d640e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "refiner_cfg = get_cfg_defaults()\n",
    "refiner_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/checkpoints/vqvae/vqvae_full/vqvae_full.yaml\")\n",
    "refiner = instantiate_from_config(refiner_cfg.vqvae).to(device).eval()\n",
    "refiner.load(os.path.join(refiner_cfg.output_dir, \"vqvae_motion.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68235ea1-2430-48a5-9c73-bb5d23cabb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd45edc-f434-4ddb-990a-75861bb063a9",
   "metadata": {},
   "source": [
    "## Generate aniamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbda16be-3bbb-449a-bd6c-5413ece5d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from core.models.generation.muse import generate_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60981426-e813-4714-aa9f-2b0f9c4a2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import MotionTokenizerParams\n",
    "from core.models.utils import instantiate_from_config, get_obj_from_str\n",
    "from core import MotionRep, AudioRep, TextRep\n",
    "from core.datasets.conditioner import ConditionProvider,ConditionFuser\n",
    "from core.models.generation.muse import MotionMuse\n",
    "\n",
    "import einops\n",
    "from configs.config_t2m import get_cfg_defaults as muse_get_cfg_defaults\n",
    "from core import MotionTokenizerParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165fb3e-96fa-4348-b928-5bbe2e9abbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10f5d9e-26ae-4e14-ab01-ea11092b6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = muse_get_cfg_defaults()\n",
    "gen_cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/checkpoints/motion_muse_body_hands/motion_muse_body_hands.yaml\")\n",
    "gen_cfg.freeze()\n",
    "tranformer_config = gen_cfg.motion_generator\n",
    "fuse_config = gen_cfg.fuser\n",
    "dataset_args = gen_cfg.dataset\n",
    "\n",
    "target = tranformer_config.pop(\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc21c7f-f0b2-411f-a213-4275d9393198",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_gen = MotionMuse(tranformer_config , fuse_config).to(device).eval()\n",
    "pkg = torch.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/checkpoints/motion_muse_body_hands/motion_muse.pt\", map_location=\"cuda\")\n",
    "motion_gen.load_state_dict(pkg[\"model\"])\n",
    "motion_gen = torch.compile(motion_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476d65d-0228-47da-8fe0-f87799e094ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83af976b-cf88-4f47-818a-0ca1968a4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync is turned on False\n",
      "loaded model with  0.03015906736254692 tensor([110000.], device='cuda:0') steps\n"
     ]
    }
   ],
   "source": [
    "body_model, left_hand_model , right_hand_model , body_cfg , left_cfg , right_cfg = load_vqvae(gen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9c6f21-47c2-4b23-90e8-b936d0376cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hays-lab/flash5/sanisetty3/miniconda3/envs/tgm3d/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "condition_provider = ConditionProvider(\n",
    "            text_conditioner_name = dataset_args.text_conditioner_name,\n",
    "            motion_rep=MotionRep(dataset_args.motion_rep),\n",
    "            audio_rep=AudioRep(dataset_args.audio_rep),\n",
    "            text_rep=TextRep(dataset_args.text_rep),\n",
    "            motion_padding=dataset_args.motion_padding,\n",
    "            audio_padding=dataset_args.audio_padding,\n",
    "            motion_max_length_s=dataset_args.motion_max_length_s,\n",
    "            audio_max_length_s=dataset_args.audio_max_length_s,\n",
    "            pad_id = MotionTokenizerParams(tranformer_config.num_tokens).pad_token_id,\n",
    "            fps=30/4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd232e3-fb1b-4a47-94a9-52c27d11d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.base_dataset import BaseMotionDataset\n",
    "base_dset = BaseMotionDataset(motion_rep=MotionRep.FULL , hml_rep= \"gpvc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "278a094a-3741-4ffd-b899-ab2db18b14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.joints2bvh import Joint2BVHConvertor\n",
    "converter = Joint2BVHConvertor(mode = \"smplx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97326e0a-0fa8-4342-8a75-1f1e71bbdcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8d121-6950-4a3d-8437-9661ddb07323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e5dcf4d-c45c-430d-bffc-31b020fb18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/beat/1_wayne_0_1_1.wav\"\n",
    "choreo = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/choreomaster/0071.wav\"\n",
    "mbr = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/aist/mBR0.wav\"\n",
    "mj = \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/aist/mJB0.wav\"\n",
    "wild =  \"/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/wild/despacito.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39769428-ba3a-4785-b2d0-bd62b79be0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_clip =  wild\n",
    "text_ = \"A person dancing energetically\"\n",
    "neg_text = None\n",
    "use_token_critic = True\n",
    "temperature = 0.6\n",
    "\n",
    "sve_file = '|'.join(t for t in text_) if isinstance(text_ , list) else f\"{text_}\"\n",
    "sve_file += \"\" if aud_clip is None else f\"{os.path.basename(aud_clip).split('.')[0]}\"\n",
    "sve_file += f\"_use_critic_{use_token_critic}_{temperature}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e48346c3-68f0-438c-b415-3f18c6a53973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person dancing energeticallydespacito_use_critic_True_0.6\n"
     ]
    }
   ],
   "source": [
    "print(sve_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e74133cf-25b5-42e3-9894-f5f786256e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 45.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 45.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 45.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 47.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 47.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 46.23it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_ids = generate_animation(motion_gen , condition_provider ,overlap = 10, duration_s = 30 , temperature = temperature, aud_file=aud_clip, text = text_ , neg_text=neg_text,use_token_critic = use_token_critic, timesteps = 24 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4b7bc-d75a-4ff7-9c49-00eb9964432f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4aba71b-de46-4655-96b4-52f53cc5501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_motion = bkn_to_motion(all_ids, base_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae800e27-3311-4f86-9812-bc8c276eec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    refiner_output = refiner(gen_motion()[None].to(device))\n",
    "    refined_motion = base_dset.toMotion(refiner_output.decoded_motion[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c372e2-6cb1-47bc-a168-fd3df1efb7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8639f6-cd61-4570-8a0b-b9cc83ae1b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e66f8-d9cd-4ef9-8da5-89b7eb7b29d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4c6f5-93e8-46d3-9cb9-b4e1b620297a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07e497-ca14-402c-b70f-838fa6e8c5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfb0a4-18a3-4e61-8d3c-501ba2d9f50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dc431dd-4229-4300-b8e4-371b14d0b286",
   "metadata": {},
   "source": [
    "### Save as gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3c325cc-a1d1-4a61-bc93-eb597d4e3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dset.render_hml(\n",
    "                    refined_motion,\n",
    "                    f\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/renders/{sve_file}_refined.gif\",\n",
    "                    zero_trans = True,\n",
    "                    zero_orient = True,\n",
    "    \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e65d895f-2d72-4a89-b3c7-2635bf8b3e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dset.render_hml(\n",
    "                    gen_motion,\n",
    "                    f\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/renders/{sve_file}.gif\",\n",
    "                    zero_trans = True,\n",
    "                    zero_orient = True,\n",
    "    \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b674f4-d492-498d-9ed5-75bf5e21c178",
   "metadata": {},
   "source": [
    "### Save as BVH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f4dc1-6de9-4466-b29f-3249fb2538ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0651340d-7d18-4bfc-a8fa-8965727c1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_inv = base_dset.inv_transform(refined_motion)\n",
    "motion_xyz = base_dset.to_xyz(motion_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d04283bc-68b7-4c50-99c9-b804864443d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ik_joint = converter.convert(motion_xyz.cpu().numpy(), filename=f\"/srv/hays-lab/scratch/sanisetty3/music_motion/MMCMG/renders/{sve_file}_refined.bvh\", iterations=10, foot_ik = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d592a73-7f61-48e0-af60-396619c06e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcbb83c1-34ad-4959-92cf-d30d453a7511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568380f8-3c35-4635-9ac8-ae3d20ff755a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ace5f-c36f-4ff3-bb27-25acab1b4fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b2fa4-dfef-4f38-a265-8d6ffbd905c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aeb855-985a-4377-9cb5-a35a98c851e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9a448-2543-41b7-86a2-4dd98791cd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c2dd6-2f75-4a46-86cf-4910de6b3719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90902baa-16e8-4eb4-ac7b-3a04e3078f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16722193-126f-4249-a173-7dd4f624494a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c5de6-cce6-4aaf-b352-90fddcfd7a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab95ff-c8c3-47c5-a49a-428c434492cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f66bd-862d-4485-9d25-1e15089b84de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf1aeb71-1581-4f34-bdce-4b2d57d26d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd697d9f-0743-4099-833a-e3a1a8ecaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import math\n",
    "\n",
    "def joinGifAud(vid , aud_clip , sve_name = \"vid\"):\n",
    "    video_clip = mp.VideoFileClip(vid)\n",
    "    audio_clip = mp.AudioFileClip(aud_clip)\n",
    "    endd = int(math.floor(min(audio_clip.end , video_clip.end)))\n",
    "    video_clip = video_clip.subclip(0, endd)\n",
    "    final_clip = video_clip.set_audio(audio_clip.subclip(0, endd))\n",
    "    save_name = os.path.basename(aud_clip).split('.')[0]\n",
    "    final_clip.write_videofile(f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/{sve_name}.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68535af4-a1b6-4c2e-b721-e5391aa8502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/hays-lab/scratch/sanisetty3/motionx/audio/wav/beat/1_wayne_0_1_1.wav'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fad651e-3a1c-4201-b09d-b5743e58d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/1_wayne_0_1_1_use_critic_True_0.4_full.mp4.\n",
      "MoviePy - Writing audio in 1_wayne_0_1_1_use_critic_True_0.4_fullTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/1_wayne_0_1_1_use_critic_True_0.4_full.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/1_wayne_0_1_1_use_critic_True_0.4_full.mp4\n"
     ]
    }
   ],
   "source": [
    "joinGifAud(f\"/srv/hays-lab/scratch/sanisetty3/music_motion/ATCMG/render/2024/{sve_file}.gif\" , aud_clip , sve_name = f\"{sve_file}_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b12855-9375-41b4-8aab-a9182779431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
